### Анализ 
Имеет смысл ориентироваться все на те же проблемы, которые возникают при работе с заказом.
Поэтому добавление логов имеет смысл в Shop API, CRM API, MES API и возможно в Messages Queue.
Api потому что происходит работа с заказом.
Messages Queue потому что транспорт.

Для прод можно использовать логи уровня INFO при работе с заказом:
- Изменение статуса заказа (время, ID покупателя, номер заказа)
- Успешное создание заказа
- Успешный расчёт стоимости в MES (ID заказа, цена)
- Запросы от API-USER при работе с MES API.(контракты)

Уровни WARN и ERROR
WARN — логируются потенциальные проблемы: просроченные заказы, слишком долгие операции, превышения лимитов.

ERROR — логируются ошибки при обработке сообщений, недоступность внешних сервисов, сбои в работе API.

Уровни DEBUG не в prod середе.
Используется локально и в стендах для отладки, содержит подробные технические детали
(stack trace, входные параметры и т. д.)

### Мотивация

Логирование позволяет получать информацию о происходящих событиях, в нашем случае с заказом.
Каждую итерацию с заказом можно обложить логами, и детально знать, что происходит в какой-либо момент времени.
Внедрение логирования:
1. Повысит уровень доверия B2B партнёров, т.к. сможем идентифицировать инцидент.
2. Упростит поиск причин проблем при обработке заказов.
3. Повысит доверие клиентов и партнёров, путем выявления проблем, при работе с заказом.
4. Снизит вероятность потери контрактов.
5. Уменьшит скорость реакции на инцидент.

Внедрение логов в первую очередь:

MES — основная точка сбоя заказов (вход из CRM, расчёт стоимости, загрузка страниц, запросы api-user)

Очередь RabbitMQ — критический компонент при транспорте заказов между сервисами.

Во вторую очередь:

Интернет-магазин,CRM


### Предлагаемое решение
1. ELK(elasticsearch, logstash, kibana)
2. На уровне контейнеров приложений java и c# свои логгеры.
3. Filebeat для передачи логов в logstash. Тут возможны разные реализации возможны реализации напрямую, 
но остановимся на классическом.
4. Logstash можно использовать для маскирования чувствительной информации.
5. Kibana для визуализации(можно и графану конечно же) тоже идем по классике.

Возможно вместо elasticsearch использовать opensearch т.к. он opensource и аналогичные этому стеку компоненты.

Логи с PII (личными данными) проходят маскирование до отправки
Аутентификация в систему и использование ролей у авторизованных пользователей "Поддержка" и "DevOps" например.
Шифрование логов на уровне хранения.

Для организации хранения использовать ILΜ для поддержания жизненного цикла индексов.
Возможно перекладывать в разные хранилища в зависимости от устаревания индекса.
Использовал бы отдельный индекс для каждой подсистемы.
Настроить время хранения, для разных статусов логов INFO, ERROR и WARN для экономии места.
Установить лимит на размер индекса, ориентировочно 100Гб. На сегменты по 10-50Гб.

### Система анализа логов
Да можно настроить алерты по числу ошибок (например, ERROR > 100 в минуту) с отправкой мессенджеры и на почту.
Искать аномалии нужно в этом может помочь визуализация частоты логов по типам событий,
аномалия это будет - резкое увеличение числа логово к средней величине во времени.
Как было описано в примере
было четыре записи о создании заказов и за секунду их стало 10 000. 
Возможно, происходит DDoS-атака конкурентами.
Или еще примеры:
Резкий рост логов "Создание заказа" — возможно, спам/атака
Множество ERROR при подключении к RabbitMQ — проблема с сетью или брокером

Все эти аномалии можно отслеживать и отсылать алерты при их возникновении.

